{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Texas school accountability data\n",
    "This notebook has the scripts needed to cut, filter and analyze school accountability data from the Texas Education Association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "Accountability data for 2013-2016 are in the `data` folder inside this repo. Here's how you could get them yourself, using the 2015 data file as an example.\n",
    "\n",
    "First: Go to the [accountability data portal](https://rptsvr1.tea.texas.gov/perfreport/account/2015/) and click the \"Download data\" link on the left rail.\n",
    "\n",
    "<img src=\"img/1-portal-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "On the resulting page, click the \"Campus-level Data\" radio button, then scroll down and click \"Continue.\"\n",
    "\n",
    "<img src=\"img/2-data-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "Finally, on the data download page, select \"Tab delimited\" from the select menu. Click the \"Select all\" button. Then click the \"Download\" button.\n",
    "\n",
    "<img src=\"img/3-download-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "I renamed this file `2015-tx-school-acc-data.dat` and dropped it into the `/data` folder, then repeated this process for 2014 and 2013.\n",
    "\n",
    "Also, I snagged the file layouts ([e.g.](https://rptsvr1.tea.texas.gov/perfreport/account/2015/download/camprate.html)) and saved them as .tsv files in the `/data` directory. In practice, however, they didn't always match up with the data, so I used them as a rough guide and consulted a sample of published summary reports [like this one](https://rptsvr1.tea.texas.gov/perfreport/account/2013/static/summary/campus/c227901170.pdf) to check expected values against actual values.\n",
    "\n",
    "Also also, I grabbed a .csv file with [spatial and contact data for every school in Texas](http://schoolsdata.tea-texas.opendata.arcgis.com/datasets/059432fd0dcb4a208974c235e837c94f_0), renamed the columns I'm going to use later (`campus_id`, `city`, `lat`, `lng`, `district_id`) and saved it as `/data/school_location_data.csv`. (TODO: grab the [districts shapefile](http://schoolsdata.tea-texas.opendata.arcgis.com/datasets/e115fed14c0f4ca5b942dc3323626b1c_0), too.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process preliminary 2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/2016-raw-data.csv', 'r') as file_in, \\\n",
    "         open('data/2016-processed-data.txt', 'w') as file_out:\n",
    "    reader = csv.reader(file_in, delimiter=',')\n",
    "    \n",
    "    \"\"\"\n",
    "    fieldnames_for_later = ['campus_id', 'campus_name', 'campus_population', 'campus_pct_disadvantaged', \n",
    "                            'campus_pct_english_language_learners', 'district_name', 'index1_target_score',\n",
    "                            'index1_score', 'index2_target_score', 'index2_score', 'index3_target_score',\n",
    "                            'index3_score', 'index4_target_score', 'index4_score', 'distinction_reading',\n",
    "                            'distinction_math', 'distinction_student_progress', 'distinction_science',\n",
    "                            'distinction_social_studies', 'distinction_close_performance_gap',\n",
    "                            'distinction_postsecondary_readiness', 'jjaep', 'daep', 'year', 'overall_rating',\n",
    "                            'updated_rating']\n",
    "    \"\"\"\n",
    "\n",
    "    fieldnames = ['campus_id', 'campus_name', 'district_name', 'rating', 'i1_target', 'i1_score',\n",
    "                  'i2_target', 'i2_score', 'i3_target', 'i3_score', 'i4_target', 'i4_score', 'year']\n",
    "    \n",
    "    writer = csv.DictWriter(file_out, fieldnames=fieldnames, delimiter=\"|\")\n",
    "    # writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        if row[1] != \"\":\n",
    "            d = {}\n",
    "            d['campus_id'] = row[3].zfill(9)\n",
    "            d['campus_name'] = row[1]\n",
    "            d['district_name'] = row[0]\n",
    "            d['rating'] = row[5]\n",
    "            d['i1_target'] = row[7]\n",
    "            d['i1_score'] = row[6]\n",
    "            d['i2_target'] = row[10]\n",
    "            d['i2_score'] = row[9]\n",
    "            d['i3_target'] = row[13]\n",
    "            d['i3_score'] = row[12]\n",
    "            d['i4_target'] = row[16]\n",
    "            d['i4_score'] = row[15]\n",
    "            d['year'] = '2016'\n",
    "            writer.writerow(d)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cut and stack\n",
    "So now I can use `awk` and `csvkit` to extract the columns I need from each file and append them to `data/stacked-file.csv`. (The file layouts are different each year.) Then I joined a few columns of location data and sorted by campus ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# truncate existing file\n",
    "# :> data/stacked_data.csv\n",
    "\n",
    "# write headers for full data\n",
    "# echo \"campus_id,campus_name,campus_population,campus_pct_disadvantaged,campus_pct_english_language_learners,district_name,index1_target_score,index1_score,index2_target_score,index2_score,index3_target_score,index3_score,index4_target_score,index4_score,distinction_reading,distinction_math,distinction_student_progress,distinction_science,distinction_social_studies,distinction_close_performance_gap,distinction_postsecondary_readiness,jjaep,daep,year,overall_rating,updated_rating\" >> data/stacked_data.csv\n",
    "\n",
    "# 2013 data\n",
    "# awk -F '\\t' '{OFS=\",\"; if (NR!=1) {print $1,$6,$44,$46,$48,$51,$20,$19,$25,$24,$30,$29,$35,$34,$5,$3,$4,\".\",\".\",\".\",\".\",$12,$11,\"2013\",$49,$50;}}' data/2013-tx-school-acc-data.dat >> data/stacked_data.csv\n",
    "\n",
    "# 2014 data\n",
    "# awk -F '\\t' '{OFS=\",\"; if (NR!=1) {print $1,$9,$49,$51,$53,$56,$23,$22,$28,$27,$33,$32,$39,$37,$6,$3,$5,$7,$8,$2,$4,$15,$13,\"2014\",$54,$55;}}' data/2014-tx-school-acc-data.dat >> data/stacked_data.csv\n",
    "\n",
    "# 2015 data\n",
    "# awk -F '\\t' '{OFS=\",\"; if (NR!=1) {print $1,$9,$49,$51,$53,$56,$23,$22,$28,$27,$33,$32,$38,$37,$6,$3,$5,$7,$8,$2,$4,$15,$13,\"2015\",$54,$55;}}' data/2015-tx-school-acc-data.dat >> data/stacked_data.csv\n",
    "\n",
    "# 2016 data\n",
    "# TODO: come back when detail data is posted and fill in\n",
    "\n",
    "# join to location data and sort by campus ID\n",
    "# csvcut -c 9,7,2,1,15 data/school_location_data.csv | csvjoin -c \"campus_id,campus_id\" data/stacked_data.csv - | csvcut -c 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29,30,31 | csvsort -c 1 > data/stacked_data_with_coordinates.csv\n",
    "\n",
    "# check for ish\n",
    "# csvclean -n data/stacked_data_with_coordinates.csv\n",
    "\n",
    "# report line count\n",
    "# wc -l data/stacked_data_with_coordinates.csv\n",
    "\n",
    "\n",
    "####  get slim version of data for 2016 interactive ####\n",
    "\n",
    "# truncate existing\n",
    ":> data/stacked_data_slim.csv\n",
    "\n",
    "# write headers\n",
    "echo \"campus_id|campus_name|district_name|rating|i1_target|i1_score|i2_target|i2_score|i3_target|i3_score|i4_target|i4_score|year\" >> data/stacked_data_slim.csv\n",
    "\n",
    "# slim version of 2013 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print$1,$6,$51,$49,$20,$19,$25,$24,$30,$29,$35,$34,\"2013\"}}' data/2013-tx-school-acc-data.dat >> data/stacked_data_slim.csv\n",
    "\n",
    "# slim version of 2014 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print $1,$9,$56,$54,$23,$22,$28,$27,$33,$32,$39,$37,\"2014\"}}' data/2014-tx-school-acc-data.dat >> data/stacked_data_slim.csv\n",
    "\n",
    "# slim version of 2015 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print $1,$9,$56,$54,$23,$22,$28,$27,$33,$32,$38,$37,\"2015\"}}' data/2015-tx-school-acc-data.dat >> data/stacked_data_slim.csv\n",
    "\n",
    "# 2016 data\n",
    "cat data/2016-processed-data.txt >> data/stacked_data_slim.csv\n",
    "\n",
    "csvclean -n data/stacked_data_slim.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Psst, future me_: I created a Python dict with a 1-indexed column layout for each year of data at `/col_index.py`.\n",
    "You're welcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the data to analyze\n",
    "Time to analyze some data. Should I use `R`, or `numpy`, or maybe `pandas`?\n",
    "\n",
    "<img src=\"img/achewood.png\" style=\"margin: 0;\" />\n",
    "\n",
    "Ha ha OK guys, settle down, I'll use `Agate`. First, create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------------+------------|\n",
      "|  column        | data_type  |\n",
      "|----------------+------------|\n",
      "|  campus_id     | Text       |\n",
      "|  campus_name   | Text       |\n",
      "|  district_name | Text       |\n",
      "|  rating        | Text       |\n",
      "|  i1_target     | Number     |\n",
      "|  i1_score      | Number     |\n",
      "|  i2_target     | Number     |\n",
      "|  i2_score      | Number     |\n",
      "|  i3_target     | Number     |\n",
      "|  i3_score      | Number     |\n",
      "|  i4_target     | Number     |\n",
      "|  i4_score      | Number     |\n",
      "|  year          | Text       |\n",
      "|----------------+------------|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import agate\n",
    "\n",
    "\"\"\"\n",
    "# Define the column types\n",
    "column_types = {\n",
    "    'campus_id': agate.Text(),\n",
    "    'campus_name': agate.Text(),\n",
    "    'campus_population': agate.Number(),\n",
    "    'campus_pct_disadvantaged': agate.Number(),\n",
    "    'campus_pct_english_language_learners': agate.Number(),\n",
    "    'district_name': agate.Text(),\n",
    "    'index1_target_score': agate.Number(),\n",
    "    'index1_score': agate.Number(),\n",
    "    'index2_target_score': agate.Number(),\n",
    "    'index2_score': agate.Number(),\n",
    "    'index3_target_score': agate.Number(),\n",
    "    'index3_score': agate.Number(),\n",
    "    'index4_target_score': agate.Number(),\n",
    "    'index4_score': agate.Number(),\n",
    "    'distinction_reading': agate.Boolean(),\n",
    "    'distinction_math': agate.Boolean(),\n",
    "    'distinction_student_progress': agate.Boolean(),\n",
    "    'distinction_science': agate.Boolean(),\n",
    "    'distinction_social_studies': agate.Boolean(),\n",
    "    'distinction_close_performance_gap': agate.Boolean(),\n",
    "    'distinction_postsecondary_readiness': agate.Boolean(),\n",
    "    'jjaep': agate.Boolean(),\n",
    "    'daep': agate.Boolean(),\n",
    "    'year': agate.Text(),\n",
    "    'overall_rating': agate.Text(),\n",
    "    'updated_rating': agate.Number(),\n",
    "    'district_id': agate.Text(),\n",
    "    'lng': agate.Number(),\n",
    "    'lat': agate.Number(),\n",
    "    'city': agate.Text()\n",
    "}\n",
    "\n",
    "school_ratings = agate.Table.from_csv('data/stacked_data_with_coordinates.csv', column_types=column_types)\n",
    "\n",
    "print(school_ratings)\n",
    "\"\"\"\n",
    "\n",
    "### slim version ###\n",
    "column_types = {    \n",
    "    'campus_id': agate.Text(),\n",
    "    'campus_name': agate.Text(),\n",
    "    'rating': agate.Text(),\n",
    "    'district_name': agate.Text(),\n",
    "    'i1_target': agate.Number(),\n",
    "    'i1_score': agate.Number(),\n",
    "    'i2_target': agate.Number(),\n",
    "    'i2_score': agate.Number(),\n",
    "    'i3_target': agate.Number(),\n",
    "    'i3_score': agate.Number(),\n",
    "    'i4_target': agate.Number(),\n",
    "    'i4_score': agate.Number(),\n",
    "    'year': agate.Text(),\n",
    "}\n",
    "\n",
    "school_ratings = agate.Table.from_csv('data/stacked_data_slim.csv', column_types=column_types, delimiter=\"|\")\n",
    "\n",
    "print(school_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data\n",
    "I need to:\n",
    "* Exclude disciplinary alternative schools (\"daep\") and kid jails (\"jjaep\").\n",
    "* Run the campus names through some text transforms to standardize names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndisciplinary_schools_count = len(school_ratings.rows) - len(school_ratings_cleaned.rows)\\n\\nprint(\\n    \"Chopped\",\\n    \"{:,}\".format(disciplinary_schools_count),\\n    \"disciplinary schools ...\"\\n)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "TEXT_TRANSFORMS = (\n",
    "    (r\"H S$\", \"High School\"),\n",
    "    (r\"MIDDLE$\", \"Middle School\"),\n",
    "    (r\"JR H S$\", \"Junior High School\"),\n",
    "    (r\"INT$\", \"Intermediate\"),\n",
    "    (r\"EL$\", \"Elementary\")\n",
    ")\n",
    "\n",
    "def clean_text(garb):\n",
    "    if garb:\n",
    "        for item in TEXT_TRANSFORMS:\n",
    "            garb = re.sub(*item, garb, flags=re.IGNORECASE)\n",
    "        return garb.title()\n",
    "\n",
    "# drop disciplinary schools\n",
    "# school_ratings_no_disc = school_ratings.where(\n",
    "#     lambda row: row['jjaep'] is False and row['daep'] is False\n",
    "#)\n",
    "\n",
    "# clean up text\n",
    "school_ratings_cleaned = school_ratings.compute([\n",
    "    ('campus_name', agate.Formula(agate.Text(), lambda row: clean_text(row['campus_name']))),\n",
    "    # ('city', agate.Formula(agate.Text(), lambda row: clean_text(row['city']))),\n",
    "    ('district_name', agate.Formula(agate.Text(), lambda row: clean_text(row['district_name'])))\n",
    "], replace=True)\n",
    "\n",
    "\"\"\"\n",
    "disciplinary_schools_count = len(school_ratings.rows) - len(school_ratings_cleaned.rows)\n",
    "\n",
    "print(\n",
    "    \"Chopped\",\n",
    "    \"{:,}\".format(disciplinary_schools_count),\n",
    "    \"disciplinary schools ...\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did local schools do this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"DIST_NAME\"\\n\"X of X schools met standard in 2016; X reported no data\"\\n\\n\\nprint(\\n    \"Pulled data for\",\\n    \"{:,}\".format(len(local_school_data.rows)),\\n    \"schools in\",\\n    \"{:,}\".format(len(local_districts)),\\n    \"local districts ...\"\\n)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csvcut -d \",\" -c 6 data/stacked_data_with_coordinates.csv | sort | uniq > districts.txt\n",
    "\n",
    "local_districts = [\"AUSTIN ACHIEVE PUBLIC SCHOOLS\", \"AUSTIN DISCOVERY SCHOOL\", \"AUSTIN ISD\", \"ROUND ROCK ISD\", \"LEANDER ISD\", \"PFLUGERVILLE ISD\", \"HAYS CISD\", \"GEORGETOWN ISD\", \"BASTROP ISD\", \"MANOR ISD\", \"LAKE TRAVIS ISD\", \"EANES ISD\", \"SAN MARCOS CISD\", \"HUTTO ISD\", \"DRIPPING SPRINGS ISD\", \"DEL VALLE ISD\"]\n",
    "\n",
    "local_school_data = school_ratings_cleaned.where(\n",
    "    lambda row: row['district_name'].upper() in local_districts\n",
    ")\n",
    "\n",
    "year_to_check = '2016'\n",
    "\n",
    "grouped_by_district = local_school_data.group_by('campus_id')\n",
    "\n",
    "for table in grouped_by_district:\n",
    "    print(table.rows.keys())\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"DIST_NAME\"\n",
    "\"X of X schools met standard in 2016; X reported no data\"\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Pulled data for\",\n",
    "    \"{:,}\".format(len(local_school_data.rows)),\n",
    "    \"schools in\",\n",
    "    \"{:,}\".format(len(local_districts)),\n",
    "    \"local districts ...\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have any schools that reported scores for all 4 standards missed every one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'index1_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d5682437d3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m missed_erry_one = school_ratings_cleaned.where(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msad_trombone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m ).order_by('campus_id')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjwinchester/Envs/school-data/lib/python3.5/site-packages/agate/table/where.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, test)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d5682437d3cb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m missed_erry_one = school_ratings_cleaned.where(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msad_trombone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m ).order_by('campus_id')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d5682437d3cb>\u001b[0m in \u001b[0;36msad_trombone\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msad_trombone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index1_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index2_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index2_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index3_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index3_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index4_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index4_target_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index1_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index2_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index2_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index3_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index3_target_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index4_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index4_target_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m missed_erry_one = school_ratings_cleaned.where(\n",
      "\u001b[0;32m/Users/cjwinchester/Envs/school-data/lib/python3.5/site-packages/agate/mapped_sequence.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'index1_score'"
     ]
    }
   ],
   "source": [
    "def sad_trombone(row):\n",
    "    if row['index1_score'] and \\\n",
    "            row['index1_target_score'] and \\\n",
    "            row['index2_score'] and \\\n",
    "            row['index2_target_score'] and \\\n",
    "            row['index3_score'] and \\\n",
    "            row['index3_target_score'] and \\\n",
    "            row['index4_score'] and \\\n",
    "            row['index4_target_score']:\n",
    "        return row['index1_score'] < row['index1_target_score'] and \\\n",
    "        row['index2_score'] < row['index2_target_score'] and \\\n",
    "        row['index3_score'] < row['index3_target_score'] and \\\n",
    "        row['index4_score'] < row['index4_target_score']\n",
    "\n",
    "missed_erry_one = school_ratings_cleaned.where(\n",
    "    lambda row: sad_trombone(row)\n",
    ").order_by('campus_id')\n",
    "\n",
    "print(\n",
    "    len(missed_erry_one.rows),\n",
    "    \"schools missed every one:\\n\"\n",
    ")\n",
    "\n",
    "for row in missed_erry_one.rows:\n",
    "    print(\n",
    "        row['campus_name'],\n",
    "        \"\\n\" + row['district_name'],\n",
    "        \"\\n\" + row['city'],\n",
    "        \"\\n\" + row['year'],\n",
    "        \"\\n\" + \"https://rptsvr1.tea.texas.gov/perfreport/account/{}/static/summary/campus/c{}.pdf\".format(row['year'], row['campus_id']),\n",
    "        \"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump to an out dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 9,135 records to file.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "outdict = {}\n",
    "index_list = []\n",
    "\n",
    "RATINGS = (\n",
    "    (r\"Met Standard\", \"M\"),\n",
    "    (r\"Met Standard\\**\", \"M\"),\n",
    "    (r\"Met Standard-Paired\", \"M\"),\n",
    "    (r\"Not Rated\", \"X\"),\n",
    "    (r\"Not Rated: Data Integrity Issues\", \"X\"),\n",
    "    (r\"Not Rated: Data Integrity Issues-Paired\", \"X\"),\n",
    "    (r\"^Z$\", \"X\"),\n",
    "    (r\"^Q$\", \"X\"),\n",
    "    (r\"^T$\", \"X\"),\n",
    "    (r\"Improvement Required-Paired\", \"I\"),\n",
    "    (r\"Improvement Required\", \"I\"),\n",
    "    (r\"Met Alternative Standard-Paired\", \"A\"),\n",
    "    (r\"Met Alternative Standard\", \"A\")\n",
    ")\n",
    "\n",
    "\n",
    "def clean_ratings(garb):\n",
    "    if garb:\n",
    "        for item in RATINGS:\n",
    "            garb = re.sub(*item, garb, flags=re.IGNORECASE)\n",
    "        return garb\n",
    "\n",
    "def de_decimalize(num, type_method):\n",
    "    \"\"\"Turn decimals into something JSON-serializable.\"\"\"\n",
    "    if num:\n",
    "        try:\n",
    "            return type_method(num)\n",
    "        except:\n",
    "            return num\n",
    "\n",
    "for row in school_ratings_cleaned.rows:\n",
    "    rating = {}\n",
    "    index1 = {}\n",
    "    index2 = {}\n",
    "    index3 = {}\n",
    "    index4 = {}\n",
    "    \n",
    "    rating['year'] = row['year']\n",
    "    rating['rating'] = clean_ratings(row['rating'])\n",
    "\n",
    "    index1['year'] = row['year']\n",
    "    index1['target'] = de_decimalize(row['i1_target'], int)\n",
    "    index1['score'] = de_decimalize(row['i1_score'], int)\n",
    "\n",
    "    index2['year'] = row['year']\n",
    "    index2['target'] = de_decimalize(row['i2_target'], int)\n",
    "    index2['score'] = de_decimalize(row['i2_score'], int)\n",
    "\n",
    "    index3['year'] = row['year']\n",
    "    index3['target'] = de_decimalize(row['i3_target'], int)\n",
    "    index3['score'] = de_decimalize(row['i3_score'], int)\n",
    "\n",
    "    index4['year'] = row['year']\n",
    "    index4['target'] = de_decimalize(row['i4_target'], int)\n",
    "    index4['score'] = de_decimalize(row['i4_score'], int)\n",
    "\n",
    "    d = outdict.get(row['campus_id'], None)\n",
    "\n",
    "    if not d:\n",
    "        outdict[row['campus_id']] = {}\n",
    "        outdict[row['campus_id']]['name'] = row['campus_name']\n",
    "        outdict[row['campus_id']]['dist_name'] = row['district_name']\n",
    "        outdict[row['campus_id']]['ratings'] = []    \n",
    "        \n",
    "    idx1 = outdict[row['campus_id']].get('1', None)\n",
    "    idx2 = outdict[row['campus_id']].get('2', None)\n",
    "    idx3 = outdict[row['campus_id']].get('3', None)\n",
    "    idx4 = outdict[row['campus_id']].get('4', None)\n",
    "\n",
    "    if not idx1:\n",
    "        outdict[row['campus_id']]['1'] = {}\n",
    "        outdict[row['campus_id']]['1']['scores'] = []\n",
    "\n",
    "    if not idx2:\n",
    "        outdict[row['campus_id']]['2'] = {}\n",
    "        outdict[row['campus_id']]['2']['scores'] = []\n",
    "\n",
    "    if not idx3:\n",
    "        outdict[row['campus_id']]['3'] = {}\n",
    "        outdict[row['campus_id']]['3']['scores'] = []\n",
    "\n",
    "    if not idx4:\n",
    "        outdict[row['campus_id']]['4'] = {}\n",
    "        outdict[row['campus_id']]['4']['scores'] = []\n",
    "        \n",
    "    outdict[row['campus_id']]['1']['scores'].append(index1)\n",
    "    outdict[row['campus_id']]['2']['scores'].append(index2)\n",
    "    outdict[row['campus_id']]['3']['scores'].append(index3)\n",
    "    outdict[row['campus_id']]['4']['scores'].append(index4)\n",
    "    outdict[row['campus_id']]['ratings'].append(rating)\n",
    "    \n",
    "# fill in missing years\n",
    "expected_years = ['2013', '2014', '2015', '2016']\n",
    "\n",
    "for school in outdict:\n",
    "    years = [x['year'] for x in outdict[school]['ratings']]\n",
    "    missing_years = [x for x in expected_years if x not in years]\n",
    "    \n",
    "    if len(missing_years) > 0:\n",
    "        for missing_year in missing_years:\n",
    "            outdict[school]['ratings'].append({\"year\": missing_year, \"rating\": None})\n",
    "\n",
    "    for i in range(1,5):\n",
    "        years = [x['year'] for x in outdict[school][str(i)]['scores']]\n",
    "        missing_years = [x for x in expected_years if x not in years]\n",
    "        if len(missing_years) > 0:\n",
    "            for missing_year in missing_years:\n",
    "                outdict[school][str(i)]['scores'].append({'target': None, 'year': missing_year, 'score': None})\n",
    "                \n",
    "    # while we're in here, sort the list of dicts by year\n",
    "    outdict[school]['ratings'] = sorted(outdict[school]['ratings'], key=itemgetter('year'))\n",
    "    outdict[school]['1']['scores'] = sorted(outdict[school]['1']['scores'], key=itemgetter('year'))\n",
    "    outdict[school]['2']['scores'] = sorted(outdict[school]['2']['scores'], key=itemgetter('year'))\n",
    "    outdict[school]['3']['scores'] = sorted(outdict[school]['3']['scores'], key=itemgetter('year'))\n",
    "    outdict[school]['4']['scores'] = sorted(outdict[school]['4']['scores'], key=itemgetter('year'))\n",
    "    \n",
    "    # write the record to its own file and add to index\n",
    "    with open(\"public/assets/data/\" + school + \".json\", \"w\") as f:\n",
    "        f.write(json.dumps(outdict[school]))\n",
    "    \n",
    "    index_list.append({\n",
    "        \"name\": outdict[school]['name'],\n",
    "        \"id\": school,\n",
    "        \"district\": outdict[school]['dist_name']\n",
    "    })\n",
    "\n",
    "\n",
    "with open('public/assets/data/search_index.json', 'w') as f:\n",
    "    f.write(json.dumps(index_list))\n",
    "    \n",
    "print(\"Wrote\", \"{:,}\".format(len(index_list)), \"records to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peep data on local schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# csvcut -d \",\" -c 6 data/stacked_data_with_coordinates.csv | sort | uniq > districts.txt\n",
    "\n",
    "\"\"\"\n",
    "local_districts = [\"AUSTIN ACHIEVE PUBLIC SCHOOLS\", \"AUSTIN DISCOVERY SCHOOL\", \"AUSTIN ISD\", \"ROUND ROCK ISD\", \"LEANDER ISD\", \"PFLUGERVILLE ISD\", \"HAYS CISD\", \"GEORGETOWN ISD\", \"BASTROP ISD\", \"MANOR ISD\", \"LAKE TRAVIS ISD\", \"EANES ISD\", \"SAN MARCOS CISD\", \"HUTTO ISD\", \"DRIPPING SPRINGS ISD\", \"DEL VALLE ISD\"]\n",
    "\n",
    "local_school_data = school_ratings_transformed.where(\n",
    "    lambda row: row['district_name'].upper() in local_districts\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Pulled data for\",\n",
    "    \"{:,}\".format(len(local_school_data.rows)),\n",
    "    \"schools in\",\n",
    "    \"{:,}\".format(len(local_districts)),\n",
    "    \"local districts ...\"\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

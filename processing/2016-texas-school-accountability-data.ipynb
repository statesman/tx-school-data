{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Texas school accountability data\n",
    "This notebook has the scripts needed to process Texas Education Association school accountability data, 2013-2016, for a Statesman interactive. Cody Winchester wrote for 2016 and Christian updated to prepare for the 2017 release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "Accountability data for 2013-2016 are in the `data` folder inside this repo. Excluding the 2016 file -- it's in a different format, in a different place -- here's how you could get the older data yourself, using the 2015 data file as an example.\n",
    "\n",
    "First: Go to the [accountability data portal](https://rptsvr1.tea.texas.gov/perfreport/account/2015/) and click the \"Download data\" link on the left rail.\n",
    "\n",
    "<img src=\"img/1-portal-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "On the resulting page, click the \"Campus-level Data\" radio button, then scroll down and click \"Continue.\"\n",
    "\n",
    "<img src=\"img/2-data-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "Finally, on the data download page, select \"Tab delimited\" from the select menu. Click the \"Select all\" button. Then click the \"Download\" button.\n",
    "\n",
    "<img src=\"img/3-download-page.gif\" style=\"border: 1px solid #ccc; margin: 20px auto 40px auto;\" />\n",
    "\n",
    "I renamed this file `2015-tx-school-acc-data.dat` and dropped it into the `/data` folder, then repeated this process for 2014 and 2013.\n",
    "\n",
    "Also, I snagged the file layouts ([e.g.](https://rptsvr1.tea.texas.gov/perfreport/account/2015/download/camprate.html)) and saved them as .tsv files in the `/data` directory. In practice, however, they didn't always match up with the data, so I used them as a rough guide and consulted a sample of published summary reports [like this one](https://rptsvr1.tea.texas.gov/perfreport/account/2013/static/summary/campus/c227901170.pdf) to check expected values against actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process preliminary 2016 data\n",
    "The initial data release for 2016, [available here as an Excel file](http://tea.texas.gov/WorkArea/linkit.aspx?LinkIdentifier=id&ItemID=51539609928), had the four top-level index scores and the \"met standard\" ratings, so that defineed our fields. The file was saved as `data/2016-raw-data.csv`, headers chopped and notes lines at bottom were deleted. The file that processed it [has been preserved from the notebook](2016-process-save.py). **The file created was `/data/2016-processed-data.txt`**.\n",
    "\n",
    "### Preparing for the 2017 data release\n",
    "The processing scripts below is set up for 2017 since 2016 is done did.\n",
    "\n",
    "We will need top open the new Excel file, chop off the headers and notes at the bottom, and save as a csv file in data. Name it `2017-raw-data.csv`. **This script currently uses test 2017 data made from a copy of 2016. PLEASE replace this with the real deal.**\n",
    "\n",
    "It's possibly that some adjustments will be needed when we get the real 2017 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ processed 2017 raw data ~\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "## processing new year\n",
    "\n",
    "## Will need to replace both input and output file here\n",
    "with open('school_data/2017-raw-data.csv', 'r') as file_in, \\\n",
    "         open('school_data/2017-processed-data.txt', 'w') as file_out:\n",
    "    reader = csv.reader(file_in, delimiter=',')\n",
    "\n",
    "\n",
    "    fieldnames = ['campus_id', 'campus_name', 'district_name', 'rating', 'i1_target', 'i1_score',\n",
    "                  'i2_target', 'i2_score', 'i3_target', 'i3_score', 'i4_target', 'i4_score', 'year']\n",
    "    \n",
    "    writer = csv.DictWriter(file_out, fieldnames=fieldnames, delimiter=\"|\")\n",
    "    # writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        if row[1] != \"\":\n",
    "            d = {}\n",
    "            # left pad to nine digits or your results will be wack\n",
    "            d['campus_id'] = row[0].zfill(9)\n",
    "            d['campus_name'] = row[23]\n",
    "            d['district_name'] = row[26]\n",
    "            d['rating'] = row[57]\n",
    "            d['i1_target'] = row[53]\n",
    "            d['i1_score'] = row[2]\n",
    "            d['i2_target'] = row[54]\n",
    "            d['i2_score'] = row[7]\n",
    "            d['i3_target'] = row[55]\n",
    "            d['i3_score'] = row[10]\n",
    "            d['i4_target'] = row[56]\n",
    "            d['i4_score'] = row[15]\n",
    "            d['year'] = '2017'\n",
    "            writer.writerow(d)\n",
    "\n",
    "print(\"~ processed 2017 raw data ~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cut and stack\n",
    "So now you can use `awk` and `csvkit` to extract the columns needed from each file and append them to `data/stacked-file.csv`. (The file layouts are different each year.) **Running this code block creates a pipe-delimited file at `data/stacked_data.txt`**\n",
    "\n",
    "**UPDATE THIS FOR 2017 WITH REAL DATA PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors.\n",
      "   43206\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# truncate file if already exists\n",
    ":> school_data/stacked_data.txt\n",
    "\n",
    "# write headers\n",
    "echo \"campus_id|campus_name|district_name|rating|i1_target|i1_score|i2_target|i2_score|i3_target|i3_score|i4_target|i4_score|year\" >> school_data/stacked_data.txt\n",
    "\n",
    "# slim version of 2013 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print$1,$6,$51,$49,$20,$19,$25,$24,$30,$29,$35,$34,\"2013\"}}' school_data/2013-tx-school-acc-data.dat >> school_data/stacked_data.txt\n",
    "\n",
    "# slim version of 2014 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print $1,$9,$56,$54,$23,$22,$28,$27,$33,$32,$39,$37,\"2014\"}}' school_data/2014-tx-school-acc-data.dat >> school_data/stacked_data.txt\n",
    "\n",
    "# slim version of 2015 data\n",
    "awk -F '\\t' '{OFS=\"|\"; if (NR!=1) {print $1,$9,$56,$54,$23,$22,$28,$27,$33,$32,$38,$37,\"2015\"}}' school_data/2015-tx-school-acc-data.dat >> school_data/stacked_data.txt\n",
    "\n",
    "# 2016 data\n",
    "cat school_data/2016-processed-data.txt >> school_data/stacked_data.txt\n",
    "\n",
    "# 2017 data THIS WILL NEED TO BE UPDATED\n",
    "cat school_data/2017-processed-data.txt >> school_data/stacked_data.txt\n",
    "\n",
    "# check for ish\n",
    "csvclean -n school_data/stacked_data.txt\n",
    "\n",
    "# report line count\n",
    "wc -l < school_data/stacked_data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and bake\n",
    "The goal here is to power an interactive, and a single JSON file with all this data is ~9MB. So we're going to group the records by school and bake out 9K individual files. **Running this code block will create ~9,000 json files in `public/assets/data`. They are NOT checked into the repo any longer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 9,317 records to file.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# create data folder if it doesn't exist\n",
    "if not os.path.exists('../public/assets/data/'):\n",
    "    os.mkdir('../public/assets/data/')\n",
    "\n",
    "outdict = {}\n",
    "index_list = []\n",
    "\n",
    "TEXT_TRANSFORMS = (\n",
    "    (r\" H S$\", \" HIGH SCHOOL\"),\n",
    "    (r\" MIDDLE$\", \" MIDDLE SCHOOL\"),\n",
    "    (r\" JR H S$\", \" JUNIOR HIGH SCHOOL\"),\n",
    "    (r\" INT$\", \" INTERMEDIATE\"),\n",
    "    (r\" EL$\", \" ELEMENTARY\"),\n",
    "    (r\"Met Standard\", \"M\"),\n",
    "    (r\"Met Standard\\**\", \"M\"),\n",
    "    (r\"Met Standard-Paired\", \"M\"),\n",
    "    (r\"Not Rated\", \"X\"),\n",
    "    (r\"Not Rated: Data Integrity Issues\", \"X\"),\n",
    "    (r\"Not Rated: Data Integrity Issues-Paired\", \"X\"),\n",
    "    (r\"^Z$\", \"X\"),\n",
    "    (r\"^Q$\", \"X\"),\n",
    "    (r\"^T$\", \"X\"),\n",
    "    (r\"Improvement Required-Paired\", \"I\"),\n",
    "    (r\"Improvement Required\", \"I\"),\n",
    "    (r\"Met Alternative Standard-Paired\", \"A\"),\n",
    "    (r\"Met Alternative Standard\", \"A\")\n",
    ")\n",
    "\n",
    "def clean_text(garb):\n",
    "    if garb:\n",
    "        for item in TEXT_TRANSFORMS:\n",
    "            garb = re.sub(*item, garb, flags=re.IGNORECASE)\n",
    "        return garb\n",
    "\n",
    "def de_decimalize(num, type_method):\n",
    "    \"\"\"Turn decimals into something JSON-serializable.\"\"\"\n",
    "    if num:\n",
    "        if num == \".\":\n",
    "            return None\n",
    "        try:\n",
    "            return type_method(num)\n",
    "        except:\n",
    "            return num\n",
    "\n",
    "with open('school_data/stacked_data.txt') as infile:\n",
    "    reader = csv.reader(infile, delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        campus_id = row[0]\n",
    "        campus_name = row[1]\n",
    "        district_name = row[2]\n",
    "        rating = row[3]\n",
    "        i1_target = row[4]\n",
    "        i1_score = row[5]\n",
    "        i2_target = row[6]\n",
    "        i2_score = row[7]\n",
    "        i3_target = row[8]\n",
    "        i3_score = row[9]\n",
    "        i4_target = row[10]\n",
    "        i4_score = row[11]\n",
    "        year = row[12]\n",
    "        \n",
    "        overall_rating = {}\n",
    "        index1 = {}\n",
    "        index2 = {}\n",
    "        index3 = {}\n",
    "        index4 = {}\n",
    "\n",
    "        overall_rating['year'] = year\n",
    "        overall_rating['rating'] = clean_text(rating)\n",
    "\n",
    "        index1['year'] = year\n",
    "        index1['target'] = de_decimalize(i1_target, int)\n",
    "        index1['score'] = de_decimalize(i1_score, int)\n",
    "\n",
    "        index2['year'] = year\n",
    "        index2['target'] = de_decimalize(i2_target, int)\n",
    "        index2['score'] = de_decimalize(i2_score, int)\n",
    "\n",
    "        index3['year'] = year\n",
    "        index3['target'] = de_decimalize(i3_target, int)\n",
    "        index3['score'] = de_decimalize(i3_score, int)\n",
    "\n",
    "        index4['year'] = year\n",
    "        index4['target'] = de_decimalize(i4_target, int)\n",
    "        index4['score'] = de_decimalize(i4_score, int)\n",
    "\n",
    "        d = outdict.get(campus_id, None)\n",
    "\n",
    "        if not d:\n",
    "            outdict[campus_id] = {}\n",
    "            outdict[campus_id]['name'] = clean_text(campus_name)\n",
    "            outdict[campus_id]['dist_name'] = clean_text(district_name)\n",
    "            outdict[campus_id]['ratings'] = []    \n",
    "\n",
    "        idx1 = outdict[campus_id].get('1', None)\n",
    "        idx2 = outdict[campus_id].get('2', None)\n",
    "        idx3 = outdict[campus_id].get('3', None)\n",
    "        idx4 = outdict[campus_id].get('4', None)\n",
    "\n",
    "        if not idx1:\n",
    "            outdict[campus_id]['1'] = {}\n",
    "            outdict[campus_id]['1']['scores'] = []\n",
    "\n",
    "        if not idx2:\n",
    "            outdict[campus_id]['2'] = {}\n",
    "            outdict[campus_id]['2']['scores'] = []\n",
    "\n",
    "        if not idx3:\n",
    "            outdict[campus_id]['3'] = {}\n",
    "            outdict[campus_id]['3']['scores'] = []\n",
    "\n",
    "        if not idx4:\n",
    "            outdict[campus_id]['4'] = {}\n",
    "            outdict[campus_id]['4']['scores'] = []\n",
    "\n",
    "        outdict[campus_id]['1']['scores'].append(index1)\n",
    "        outdict[campus_id]['2']['scores'].append(index2)\n",
    "        outdict[campus_id]['3']['scores'].append(index3)\n",
    "        outdict[campus_id]['4']['scores'].append(index4)\n",
    "        outdict[campus_id]['ratings'].append(overall_rating)\n",
    "\n",
    "    # fill in missing years\n",
    "    expected_years = ['2013', '2014', '2015', '2016', '2017']\n",
    "\n",
    "    for school in outdict:\n",
    "        years = [x['year'] for x in outdict[school]['ratings']]\n",
    "        missing_years = [x for x in expected_years if x not in years]\n",
    "\n",
    "        if len(missing_years) > 0:\n",
    "            for missing_year in missing_years:\n",
    "                outdict[school]['ratings'].append({\"year\": missing_year, \"rating\": None})\n",
    "\n",
    "        for i in range(1,5):\n",
    "            years = [x['year'] for x in outdict[school][str(i)]['scores']]\n",
    "            missing_years = [x for x in expected_years if x not in years]\n",
    "            if len(missing_years) > 0:\n",
    "                for missing_year in missing_years:\n",
    "                    outdict[school][str(i)]['scores'].append({'target': None, 'year': missing_year, 'score': None})\n",
    "\n",
    "        # sort the list of dicts by year\n",
    "        outdict[school]['ratings'] = sorted(outdict[school]['ratings'], key=itemgetter('year'), reverse=True)\n",
    "        outdict[school]['1']['scores'] = sorted(outdict[school]['1']['scores'], key=itemgetter('year'), reverse=True)\n",
    "        outdict[school]['2']['scores'] = sorted(outdict[school]['2']['scores'], key=itemgetter('year'), reverse=True)\n",
    "        outdict[school]['3']['scores'] = sorted(outdict[school]['3']['scores'], key=itemgetter('year'), reverse=True)\n",
    "        outdict[school]['4']['scores'] = sorted(outdict[school]['4']['scores'], key=itemgetter('year'), reverse=True)\n",
    "\n",
    "        # write the record to its own file and add to index\n",
    "        with open(\"../public/assets/data/\" + school + \".json\", \"w\") as f:\n",
    "            f.write(json.dumps(outdict[school]))\n",
    "\n",
    "        index_list.append({\n",
    "            \"name\": outdict[school]['name'],\n",
    "            \"id\": school,\n",
    "            \"district\": outdict[school]['dist_name']\n",
    "        })\n",
    "        \n",
    "with open('../public/assets/data/search_index.json', 'w') as f:\n",
    "    f.write(json.dumps(index_list))\n",
    "    \n",
    "print(\"Wrote\", \"{:,}\".format(len(index_list)), \"records to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
